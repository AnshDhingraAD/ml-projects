# -*- coding: utf-8 -*-
"""pro2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eAZHc_dQ3Nj1kfliHhMbuvvdDsAmSB3k
"""

from google.colab import files

# Upload the file
uploaded = files.upload()

# Access the uploaded file (assuming it's a text file)
for file_name in uploaded.keys():
    with open(file_name, 'r') as file:
        content = file.read()

from sklearn.datasets import load_iris

iris=load_iris()
type(iris)

print (iris.data)

print(iris.feature_names)

print(iris.target)

print(iris.target_names)

print (type(iris.data))

print(type(iris.target))

print(iris.data.shape)

print (iris.target.shape)

X=iris.data
y=iris.target

print(X.shape)
print(y.shape)

from sklearn.neighbors import KNeighborsClassifier

knn=KNeighborsClassifier(n_neighbors=1)

print(knn)

knn.fit(X,y)

X_new=[[3,5,4,2],[5,4,3,2]]

knn.predict(X_new)

knn=KNeighborsClassifier(n_neighbors=5)
knn.fit(X,y)
knn.predict(X_new)

from sklearn.linear_model import LogisticRegression
logreg=LogisticRegression()
logreg.fit(X,y)
logreg.predict(X_new)

logreg.predict(X)

y_pred=logreg.predict(X)
len(y_pred)

from sklearn import metrics
print(metrics.accuracy_score(y,y_pred))

y_predknn=knn.predict(X)
print(metrics.accuracy_score(y,y_predknn))

knn=KNeighborsClassifier(n_neighbors=1)
knn.fit(X,y)
knn.predict(X_new)

y_predknn1=knn.predict(X)
print(metrics.accuracy_score(y,y_predknn1))

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.4,random_state=1)

print(X_train.shape)
print(y_test.shape)

print(y_train.shape)
print(y_test.shape)

y_pred=logreg.predict(X_test)
print(metrics.accuracy_score(y_test,y_pred))

knn=KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train,y_train)
y_pred=knn.predict(X_test)
print(metrics.accuracy_score(y_test,y_pred))

knn=KNeighborsClassifier(n_neighbors=1)
knn.fit(X_train,y_train)
y_pred=knn.predict(X_test)
print(metrics.accuracy_score(y_test,y_pred))

k_range=range(1,25)
scores=[]
for k in k_range:
    knn=KNeighborsClassifier(n_neighbors=k)
    knn.fit(X_train,y_train)
    y_pred=knn.predict(X_test)
    scores.append(metrics.accuracy_score(y_test,y_pred))

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline

plt.plot(k_range,scores)
plt.grid()
plt.xlabel("value of k level in knn")
plt.ylabel("Testing Accuracy")

knn=KNeighborsClassifier(n_neighbors=5)
knn.fit(X,y)
knn.predict([[3,5,4,2],[5.1, 3.5, 1.4, 0.2]])

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
# Import enable_iterative_imputer before importing IterativeImputer
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer
from sklearn.metrics import mean_squared_error, mean_absolute_error

# Step 1: Data Overview
# Original dataset (ground truth)
data = pd.DataFrame({
    'Feature1': np.random.rand(100),
    'Feature2': np.random.rand(100),
    'Feature3': np.random.rand(100)
})

# Simulate missing data
np.random.seed(42)
data_with_missing = data.copy()
missing_mask = np.random.rand(*data.shape) < 0.2
data_with_missing[missing_mask] = np.nan

# Step 2: Impute missing data using IterativeImputer
imputer = IterativeImputer(max_iter=10, random_state=42)
imputed_data = pd.DataFrame(imputer.fit_transform(data_with_missing), columns=data.columns)

# Step 3: Calculate metrics
missing_positions = missing_mask
true_values = data[missing_positions]
imputed_values = imputed_data[missing_positions]

mse = mean_squared_error(true_values, imputed_values)
rmse = np.sqrt(mse)
mae = mean_absolute_error(true_values, imputed_values)

# Step 4: Generate report
report = {
    "Total Missing Values": data_with_missing.isnull().sum().sum(),
    "MSE": mse,
    "RMSE": rmse,
    "MAE": mae
}
report_df = pd.DataFrame(report, index=[0])
print("Report Summary:")
print(report_df)

# Step 5: Visualizations
plt.figure(figsize=(15, 5))

# Missing data visualization
plt.subplot(1, 3, 1)
sns.heatmap(data_with_missing.isnull(), cbar=False, cmap='viridis')
plt.title("Missing Data Pattern")

# Original vs Imputed Data
plt.subplot(1, 3, 2)
sns.kdeplot(data['Feature1'], label='Original', color='blue')
sns.kdeplot(imputed_data['Feature1'], label='Imputed', color='red')
plt.title("Feature 1 Distribution")
plt.legend()

# Error Distribution
plt.subplot(1, 3, 3)
errors = true_values - imputed_values
sns.histplot(errors.values.flatten(), kde=True, color='purple')
plt.title("Imputation Error Distribution")

plt.tight_layout()
plt.show()

report_df.to_csv("imputation_report.csv", index=False)
plt.savefig("imputation_visualizations2.png")

import pickle

# Save the model
with open('model2.pkl', 'wb') as f:
    pickle.dump(model, f)

import pickle

# Assuming 'knn' is the model you want to save
with open('model2.pkl', 'wb') as f:
    pickle.dump(knn, f) # Changed 'model' to 'knn'